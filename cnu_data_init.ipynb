{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 설정 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySQL 서버에 연결되었습니다. 버전: 9.3.0\n",
      "현재 데이터베이스: cnu_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kv/jv4ntr9x5h3f_0rbw1xytqbm0000gp/T/ipykernel_81382/3892527287.py:17: DeprecationWarning: Call to deprecated function get_server_info. Reason: \n",
      "    The property counterpart 'server_info' should be used instead.\n",
      "\n",
      "  db_info = connection.get_server_info()\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "\n",
    "connection = None\n",
    "\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        port=3306,\n",
    "        database='cnu_data',\n",
    "        user='root',\n",
    "        password='dydrkfl#7!'\n",
    "    )\n",
    "    \n",
    "    if connection.is_connected():\n",
    "        db_info = connection.get_server_info()\n",
    "        print(f\"MySQL 서버에 연결되었습니다. 버전: {db_info}\")\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(\"select database();\")\n",
    "        record = cursor.fetchone()\n",
    "        print(f\"현재 데이터베이스: {record[0]}\")\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"MySQL 연결 중 에러 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime \n",
    "def log_api_error(endpoint, error_message):\n",
    "    \"\"\"\n",
    "    API 호출 에러를 로그 파일에 기록하는 함수\n",
    "    \n",
    "    Args:\n",
    "        endpoint (str): API 엔드포인트 URL\n",
    "        error_message (str): 발생한 에러 메시지\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open('api_log.log', 'a', encoding='utf-8') as log_file:\n",
    "            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "            log_entry = f\"[{timestamp}] API 호출 실패\\n\"\n",
    "            log_entry += f\"엔드포인트: {endpoint}\\n\"\n",
    "            log_entry += f\"에러 메시지: {error_message}\\n\"\n",
    "            log_entry += \"-\" * 80 + \"\\n\"\n",
    "            log_file.write(log_entry)\n",
    "    except Exception as e:\n",
    "        print(f\"로그 파일 작성 중 에러 발생: {e}\")\n",
    "\n",
    "def fetch_data(endpoint) -> list:\n",
    "    \"\"\"\n",
    "    CNU API에서 데이터를 가져오는 함수\n",
    "    \n",
    "    Args:\n",
    "        endpoint (str): API 엔드포인트 URL\n",
    "        \n",
    "    Returns:\n",
    "        dict: API 응답 데이터\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # 제어 문자 필터링\n",
    "    # - ASCII 32 미만의 제어문자 제거 (\\n, \\r, \\t 제외)\n",
    "    # - ASCII 127 (DEL) 제거\n",
    "    # - ASCII 128-159 사이의 제어문자 제거\n",
    "    # - 유니코드 한글 범위 (AC00-D7AF) 허용\n",
    "    # - 기본 ASCII 문자 (32-126) 허용\n",
    "    cleaned_text = ''.join(ch for ch in response.text \n",
    "                            if (ord(ch) >= 32 and ord(ch) <= 126) # 기본 ASCII\n",
    "                            or ch in {'\\n', '\\r', '\\t'} # 허용된 제어문자\n",
    "                            or (0xAC00 <= ord(ch) <= 0xD7AF) # 한글 유니코드\n",
    "                            or (ord(ch) > 159)) # 그 외 유니코드 문자\n",
    "    \n",
    "    data = json.loads(cleaned_text)\n",
    "    print(f\"API 응답 상태: {response.status_code}\")\n",
    "    \n",
    "    # MSG 필드가 success를 포함하는지 확인\n",
    "    if ('OutBlock' not in data and 'outBlock' not in data) or \\\n",
    "   (not data.get('OutBlock') and not data.get('outBlock')) or \\\n",
    "   ('MSG' not in (data.get('OutBlock', [{}])[0] if data.get('OutBlock') else data.get('outBlock', [{}])[0])) or \\\n",
    "   'success' not in ((data.get('OutBlock', [{}])[0].get('MSG', '') if data.get('OutBlock') else data.get('outBlock', [{}])[0].get('MSG', ''))):\n",
    "       raise Exception(f\"API 응답 실패 in {endpoint}: {data}\")\n",
    "    \n",
    "    return data[\"RESULT\"]\n",
    "    \n",
    "\n",
    "import csv\n",
    "def dict_to_csv(data: dict, output_file_name: str):\n",
    "    \"\"\"\n",
    "    딕셔너리 형태의 데이터를 CSV 파일로 변환하는 함수\n",
    "    \n",
    "    Args:\n",
    "        data (dict): 변환할 딕셔너리 데이터. 모든 value는 같은 길이의 리스트여야 함\n",
    "        output_file (str): 저장할 CSV 파일명\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 데이터가 비어있는지 확인\n",
    "        if not data or not all(isinstance(v, list) for v in data.values()):\n",
    "            raise ValueError(\"데이터가 올바른 형식이 아닙니다.\")\n",
    "            \n",
    "        # 모든 리스트의 길이가 같은지 확인\n",
    "        list_lengths = [len(v) for v in data.values()]\n",
    "        if len(set(list_lengths)) > 1:\n",
    "            raise ValueError(\"모든 리스트의 길이가 같아야 합니다.\")\n",
    "            \n",
    "        # CSV 파일 생성\n",
    "        with open(f\"{output_file_name}.csv\", 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            \n",
    "            # 헤더(컬럼명) 작성\n",
    "            writer.writerow(data.keys())\n",
    "            \n",
    "            # 데이터 작성\n",
    "            rows = zip(*data.values())\n",
    "            writer.writerows(rows)\n",
    "            \n",
    "        print(f\"CSV 파일이 성공적으로 생성되었습니다: {output_file_name}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"CSV 파일 생성 중 에러 발생: {e}\")\n",
    "\n",
    "# TODO: 수강신청 데이터 전처리 전략 세우기(수강신청을 얼마나 많이 했는지 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTH_KEY = '081E3B5B5C5E47409E3AB0BE3FBFC9FDC7798045'\n",
    "CNU_API_ENDPOINT = 'https://api.cnu.ac.kr/svc/offcam/pub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 강의계획서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강의계획서 테이블이 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 강의계획서 테이블 생성\n",
    "try:\n",
    "    if connection.is_connected():\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS lecture_plan (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            year INT NOT NULL,\n",
    "            semester VARCHAR(10) NOT NULL,\n",
    "            target_year INT,\n",
    "            organization_type VARCHAR(20),\n",
    "            college VARCHAR(50),\n",
    "            department VARCHAR(100),\n",
    "            subject_no VARCHAR(20),\n",
    "            subject_name VARCHAR(200),\n",
    "            class_division VARCHAR(10),\n",
    "            subject_type VARCHAR(50),\n",
    "            credit INT,\n",
    "            theory_hours INT,\n",
    "            practice_hours INT,\n",
    "            summary TEXT,\n",
    "            subject_description TEXT,\n",
    "            textbook TEXT,\n",
    "            reference_book TEXT,\n",
    "            prerequisite TEXT,\n",
    "            professor VARCHAR(100),\n",
    "            timetable TEXT,\n",
    "            lesson_type VARCHAR(50),\n",
    "            evaluation_method VARCHAR(50),\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "        print(\"강의계획서 테이블이 생성되었습니다.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"테이블 생성 중 오류 발생: {str(e)}\")\n",
    "\n",
    "# 데이터 저장\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO lecture_plan (\n",
    "    year, semester, target_year, organization_type, college, department,\n",
    "    subject_no, subject_name, class_division, subject_type, credit,\n",
    "    theory_hours, practice_hours, summary, subject_description,\n",
    "    textbook, reference_book, prerequisite, professor, timetable,\n",
    "    lesson_type, evaluation_method\n",
    ") VALUES (\n",
    "    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,\n",
    "    %s, %s, %s, %s, %s, %s, %s\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집 및 저장\n",
    "\n",
    "# 진행 상태를 저장/불러오기 위한 파일명\n",
    "PROGRESS_FILE = 'lecture_scraping_progress.txt'\n",
    "\n",
    "# 이전 진행상태 불러오기\n",
    "def load_progress():\n",
    "    try:\n",
    "        with open(PROGRESS_FILE, 'r') as f:\n",
    "            year, semester, page, data_idx = map(int, f.read().strip().split(','))\n",
    "        return year, semester, page, data_idx\n",
    "    except FileNotFoundError:\n",
    "        return 2022, 1, 1, 0  # 초기값\n",
    "\n",
    "# 현재 진행상태 저장\n",
    "def save_progress(year, semester, page, data_idx):\n",
    "    with open(PROGRESS_FILE, 'w') as f:\n",
    "        f.write(f\"{year},{semester},{page},{data_idx}\")\n",
    "\n",
    "# 저장된 진행상태 불러오기\n",
    "current_year, current_semester, current_page, current_data_idx = load_progress()\n",
    "\n",
    "for year in range(current_year, 2025+1):\n",
    "    for semester in range(current_semester, 2+1):\n",
    "        page = current_page if year == current_year and semester == current_semester else 1\n",
    "        while True:\n",
    "            endpoint = f'{CNU_API_ENDPOINT}/lsnSmry?AUTH_KEY={AUTH_KEY}&P_YR={year}&P_OPEN_SHTM_CD={semester}&page={page}'\n",
    "            \n",
    "            # API 호출\n",
    "            data = fetch_data(endpoint)\n",
    "            \n",
    "            if not data:\n",
    "                break\n",
    "                \n",
    "            try:     \n",
    "                start_idx = current_data_idx if year == current_year and semester == current_semester and page == current_page else 0\n",
    "                for idx, lecture in enumerate(data[start_idx:], start=start_idx):\n",
    "                    values = (\n",
    "                        lecture['OPEN_YR'],\n",
    "                        lecture['SHTM'],\n",
    "                        lecture['TRGT_SHYR'],\n",
    "                        lecture['ORGN_CLSF_CD'],\n",
    "                        lecture['COLG'],\n",
    "                        lecture['DEGR_NM_SUST'],\n",
    "                        lecture['OPEN_SBJT_NO'],\n",
    "                        lecture['OPEN_SBJT_NM'],\n",
    "                        lecture['OPEN_DCLSS'],\n",
    "                        lecture['CPTN_DIV_NM'],\n",
    "                        lecture['PNT'],\n",
    "                        lecture['THEO_TMCNT'],\n",
    "                        lecture['PRAC_TMCNT'],\n",
    "                        lecture['LSN_SMRY'],\n",
    "                        lecture['SBJT_SHT'],\n",
    "                        lecture['TEMT_REF_LITRT'],\n",
    "                        lecture['REF_BOOK'],\n",
    "                        lecture['PRE_LRN_CN'],\n",
    "                        lecture['PROF_INFO'],\n",
    "                        lecture['TMTBL_INFO'],\n",
    "                        lecture['LSN_TYPE_NM'],\n",
    "                        lecture['MRKS_EVL_MTHD_NM']\n",
    "                    )\n",
    "                    cursor.execute(insert_query, values)\n",
    "                    # 현재 진행상태 저장\n",
    "                    save_progress(year, semester, page, idx + 1)\n",
    "                \n",
    "                connection.commit()\n",
    "                print(f\"{year}년 {semester}학기 {page}페이지 데이터 저장 완료\")\n",
    "                \n",
    "                # 페이지 정보 확인\n",
    "                if page >= int(data[0]['PAGECNT']):\n",
    "                    current_data_idx = 0  # 다음 학기/연도로 넘어갈 때 초기화\n",
    "                    break\n",
    "                    \n",
    "                page += 1\n",
    "                current_data_idx = 0  # 다음 페이지로 넘어갈 때 초기화\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"데이터 저장 중 오류 발생: {str(e)}\")\n",
    "                # 오류 발생 시 현재 진행상태가 저장되어 있으므로 다음 실행 시 이어서 진행 가능\n",
    "                break\n",
    "        current_semester = 1  # 다음 연도로 넘어갈 때 학기 초기화\n",
    "    current_page = 1  # 다음 연도로 넘어갈 때 페이지 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNU 게시판 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f'{CNU_API_ENDPOINT}/cmsBoard?AUTH_KEY={AUTH_KEY}'\n",
    "\n",
    "# API 호출\n",
    "data = fetch_data(endpoint)\n",
    "board_nums = []\n",
    "# 테이블 및 컬럼 생성성\n",
    "try:\n",
    "    if connection.is_connected():\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # 1. 게시판 정보 테이블 생성\n",
    "        create_table_query = \"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS board_info (\n",
    "            id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "            site_nm VARCHAR(100) NOT NULL,\n",
    "            board_no VARCHAR(20) NOT NULL,\n",
    "            board_nm VARCHAR(200) NOT NULL,\n",
    "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "        )\n",
    "        \"\"\"\n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "        \n",
    "        insert_query = \"\"\"\n",
    "            INSERT INTO board_info (site_nm, board_no, board_nm)\n",
    "            VALUES (%s, %s, %s)\n",
    "            \"\"\"\n",
    "        # 2. API 응답 데이터를 DB에 저장\n",
    "        if len(data) > 0:\n",
    "            # 데이터를 순회하며 DB에 저장\n",
    "            for board in data:\n",
    "                board_nums.append(board['board_no'])\n",
    "                \n",
    "                values = (\n",
    "                    board['site_nm'].strip(),\n",
    "                    board['board_no'],\n",
    "                    board['board_nm']\n",
    "                )\n",
    "                cursor.execute(insert_query, values)\n",
    "            \n",
    "            connection.commit()\n",
    "            print(f\"{len(data)}개의 게시판 정보가 DB에 저장되었습니다.\")\n",
    "        \n",
    "except Error as e:\n",
    "    print(f\"MySQL 연결/처리 중 에러 발생: {e}\")\n",
    "    \n",
    "finally:\n",
    "    if 'connection' in locals() and connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "        print(\"MySQL 연결이 종료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNU 게시판 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/choiyt3465/.local/lib/python3.11/site-packages (from beautifulsoup4) (4.13.2)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.4 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# 1. 게시글 내용 테이블 생성\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS board_contents (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    board_no INT NOT NULL,\n",
    "    article_no INT NOT NULL,\n",
    "    article_title VARCHAR(500) NOT NULL,\n",
    "    article_text TEXT,\n",
    "    writer_nm VARCHAR(100),\n",
    "    click_cnt INT,\n",
    "    attach_cnt INT,\n",
    "    update_dt DATETIME,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "\"\"\"\n",
    "cursor.execute(create_table_query)\n",
    "connection.commit()\n",
    "\n",
    "# 2. API 응답 데이터를 DB에 저장\n",
    "insert_query = \"\"\"\n",
    "INSERT INTO board_contents \n",
    "(board_no, article_no, article_title, article_text, writer_nm, click_cnt, attach_cnt, update_dt)\n",
    "VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = connection.cursor()\n",
    "cursor.execute(\"SELECT board_no FROM board_info\")\n",
    "board_nums = [row[0] for row in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진행 상태를 저장할 파일 경로\n",
    "progress_file = 'board_scraping_progress.txt'\n",
    "\n",
    "# 이전 진행 상태 확인\n",
    "try:\n",
    "    with open(progress_file, 'r') as f:\n",
    "        last_index = int(f.read().strip())\n",
    "    board_nums = board_nums[last_index:]\n",
    "    print(f\"이전 진행 상태에서 재개합니다. (인덱스: {last_index})\")\n",
    "except FileNotFoundError:\n",
    "    last_index = 0\n",
    "    print(\"처음부터 시작합니다.\")\n",
    "\n",
    "try:\n",
    "    for i, p_board_no in enumerate(board_nums, start=last_index):\n",
    "        endpoint = f'{CNU_API_ENDPOINT}/homepageboardContents?AUTH_KEY={AUTH_KEY}&P_board_no={board_nums[i]}'\n",
    "        # API 호출\n",
    "        data = fetch_data(endpoint)\n",
    "        \n",
    "        for article in data:\n",
    "            # HTML 태그 제거\n",
    "            clean_text = BeautifulSoup(article['article_text'], 'html.parser').get_text()\n",
    "            clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "            \n",
    "            # 날짜 포맷팅\n",
    "            update_date = datetime.datetime(\n",
    "                year=article['update_dt']['year'] + 1900,  # year 값이 1900년 기준이므로 보정\n",
    "                month=article['update_dt']['month'] + 1,   # month는 0-based이므로 1 추가\n",
    "                day=article['update_dt']['date'],\n",
    "                hour=article['update_dt']['hours'],\n",
    "                minute=article['update_dt']['minutes']\n",
    "            )\n",
    "            \n",
    "            values = (\n",
    "                article['board_no'],\n",
    "                article['article_no'],\n",
    "                article['article_title'],\n",
    "                clean_text,\n",
    "                article['writer_nm'],\n",
    "                article['click_cnt'],\n",
    "                article['attach_cnt'],\n",
    "                update_date\n",
    "            )\n",
    "            cursor.execute(insert_query, values)\n",
    "        \n",
    "        connection.commit()\n",
    "        print(f\"게시판 {p_board_no}: {len(data)}개의 게시글이 DB에 저장되었습니다.\")\n",
    "        \n",
    "        # 진행 상태 저장\n",
    "        with open(progress_file, 'w') as f:\n",
    "            f.write(str(i + 1))\n",
    "\n",
    "except Error as e:\n",
    "    print(f\"MySQL 연결/처리 중 에러 발생: {e}\")\n",
    "    connection.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수강신청"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테이블 생성\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS sugang_info (\n",
    "    id VARCHAR(50) PRIMARY KEY,\n",
    "    pagecnt VARCHAR(10),\n",
    "    cnt INT,\n",
    "    open_yr VARCHAR(4),\n",
    "    cptn_div VARCHAR(50),\n",
    "    sbjt_nm VARCHAR(100),\n",
    "    open_sbjt_no VARCHAR(20),\n",
    "    open_dclss VARCHAR(10),\n",
    "    dgn_sbjt_yn VARCHAR(1),\n",
    "    ogdp_cors VARCHAR(20),\n",
    "    ogdp_dan VARCHAR(20),\n",
    "    ogdp_orgn_clsf VARCHAR(20),\n",
    "    ogdp_shyr INT,\n",
    "    open_shtm VARCHAR(20),\n",
    "    open_sust_mj VARCHAR(100),\n",
    "    tlsn_aply_dt VARCHAR(50),\n",
    "    sugang_count INT DEFAULT 0,\n",
    "    api_call_idx VARCHAR(20)\n",
    ")\"\"\"\n",
    "\n",
    "cursor.execute(create_table_query)\n",
    "connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 진행상태 파일\n",
    "progress_file = 'sugang_progress.txt'\n",
    "\n",
    "# 진행상태 복구\n",
    "if os.path.exists(progress_file):\n",
    "    with open(progress_file, 'r') as f:\n",
    "        p_yr, page, idx = map(int, f.read().split(','))\n",
    "else:\n",
    "    p_yr = 2023\n",
    "    page = 1\n",
    "    idx = 0\n",
    "\n",
    "try:\n",
    "    while p_yr <= 2025:\n",
    "        # 첫 페이지에서 전체 페이지 수 확인\n",
    "        endpoint = f'{CNU_API_ENDPOINT}/SugangInfo?AUTH_KEY={AUTH_KEY}&P_OPEN_YR={p_yr}&page={page}'\n",
    "        data = fetch_data(endpoint)\n",
    "        if not data:\n",
    "            continue\n",
    "            \n",
    "        total_pages = int(data[0]['PAGECNT'])\n",
    "        \n",
    "        while page <= total_pages:\n",
    "            try:\n",
    "                if page > 1:\n",
    "                    endpoint = f'{CNU_API_ENDPOINT}/SugangInfo?AUTH_KEY={AUTH_KEY}&P_OPEN_YR={p_yr}&page={page}'\n",
    "                    data = fetch_data(endpoint)\n",
    "            \n",
    "                for idx, item in enumerate(data, start=idx):\n",
    "                    # ID 생성\n",
    "                    id = f\"{item['OPEN_YR']}-{item['OPEN_SHTM']}-{item['OPEN_DCLSS']}_{item['OPEN_SBJT_NO']}\"\n",
    "                    api_call_idx = f\"{p_yr}{page}-{idx}\"\n",
    "                    \n",
    "                    # 중복 체크 및 처리\n",
    "                    check_query = \"SELECT id FROM sugang_info WHERE id = %s\"\n",
    "                    cursor.execute(check_query, (id,))\n",
    "                    \n",
    "                    if cursor.fetchone():\n",
    "                        # 중복된 경우 카운트 증가 및 api_call_idx 업데이트\n",
    "                        update_query = \"\"\"\n",
    "                        UPDATE sugang_info \n",
    "                        SET sugang_count = sugang_count + 1,\n",
    "                            api_call_idx = %s \n",
    "                        WHERE id = %s\n",
    "                        \"\"\"\n",
    "                        cursor.execute(update_query, (api_call_idx, id))\n",
    "                    else:\n",
    "                        # 새로운 데이터 삽입\n",
    "                        insert_query = \"\"\"\n",
    "                        INSERT INTO sugang_info VALUES (\n",
    "                            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n",
    "                        )\"\"\"\n",
    "                        values = (\n",
    "                            id, item['PAGECNT'], item['CNT'], item['OPEN_YR'],\n",
    "                            item['CPTN_DIV'], item['SBJT_NM'], item['OPEN_SBJT_NO'],\n",
    "                            item['OPEN_DCLSS'], item['DGN_SBJT_YN'], item['OGDP_CORS'],\n",
    "                            item['OGDP_DAN'], item['OGDP_ORGN_CLSF'], item['OGDP_SHYR'],\n",
    "                            item['OPEN_SHTM'], item['OPEN_SUST_MJ'], item['TLSN_APLY_DT'],\n",
    "                            0, api_call_idx\n",
    "                        )\n",
    "                        cursor.execute(insert_query, values)\n",
    "                \n",
    "                # 현재 페이지의 모든 처리가 성공하면 커밋\n",
    "                connection.commit()\n",
    "                print(f\"년도 {p_yr}, 페이지 {page}/{total_pages} 처리 완료\")\n",
    "                \n",
    "                # 진행상태 저장\n",
    "                with open(progress_file, 'w') as f:\n",
    "                    f.write(f\"{p_yr},{page},{idx}\")\n",
    "                    \n",
    "                page += 1\n",
    "                idx = 0  # 페이지가 바뀌면 idx 초기화\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"에러 발생 (년도: {p_yr}, 페이지: {page}): {str(e)}\")\n",
    "                # 현재 페이지의 트랜잭션만 롤백\n",
    "                raise\n",
    "                \n",
    "        # 년도 증가, 페이지 초기화\n",
    "        p_yr += 1\n",
    "        page = 1\n",
    "        idx = 0  # 년도가 바뀌면 idx 초기화\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"처리 중 에러 발생: {str(e)}\")\n",
    "    # 진행상태는 이미 저장되어 있으므로 다음 실행시 이어서 처리 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 파일이 성공적으로 생성되었습니다: lecture_plan\n",
      "데이터베이스 테이블 lecture_plan을(를) CSV 파일로 내보내기 완료\n",
      "CSV 파일이 성공적으로 생성되었습니다: sugang_info\n",
      "데이터베이스 테이블 sugang_info을(를) CSV 파일로 내보내기 완료\n",
      "CSV 파일이 성공적으로 생성되었습니다: board_info\n",
      "데이터베이스 테이블 board_info을(를) CSV 파일로 내보내기 완료\n"
     ]
    }
   ],
   "source": [
    "# 데이터베이스에서 CSV로 내보내기\n",
    "def export_db_to_csv(connection, table_name: str):\n",
    "    \"\"\"\n",
    "    데이터베이스 테이블의 내용을 CSV 파일로 내보내는 함수\n",
    "    \n",
    "    Args:\n",
    "        connection: MySQL 데이터베이스 연결 객체\n",
    "        table_name (str): 내보낼 테이블 이름\n",
    "        output_file (str): 저장할 CSV 파일명\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            port=3306,\n",
    "            database='cnu_data',\n",
    "            user='root',\n",
    "            password='dydrkfl#7!'\n",
    "        )\n",
    "        \n",
    "        cursor = connection.cursor(dictionary=True)\n",
    "        \n",
    "        # 테이블의 모든 데이터 조회\n",
    "        query = f\"SELECT * FROM {table_name}\"\n",
    "        cursor.execute(query)\n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        if not rows:\n",
    "            print(f\"테이블 {table_name}에 데이터가 없습니다.\")\n",
    "            return\n",
    "            \n",
    "        # 딕셔너리 형태로 변환\n",
    "        data = {key: [] for key in rows[0].keys()}\n",
    "        for row in rows:\n",
    "            for key, value in row.items():\n",
    "                data[key].append(value)\n",
    "                \n",
    "        # CSV 파일로 저장\n",
    "        dict_to_csv(data, table_name)\n",
    "        \n",
    "        cursor.close()\n",
    "        print(f\"데이터베이스 테이블 {table_name}을(를) CSV 파일로 내보내기 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"데이터베이스 내보내기 중 에러 발생: {e}\")\n",
    "\n",
    "# 수강 정보 테이블을 CSV 파일로 내보내기\n",
    "export_db_to_csv(connection, \"lecture_plan\")\n",
    "export_db_to_csv(connection, \"sugang_info\")\n",
    "export_db_to_csv(connection, \"board_info\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def create_table_from_csv(connection, csv_file_path: str, table_name: str):\n",
    "    \"\"\"\n",
    "    CSV 파일의 구조를 기반으로 데이터베이스 테이블을 생성하는 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # NaN 값을 None으로 변환\n",
    "        df = df.replace({pd.NA: None, pd.NaT: None, 'nan': None})\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "        \n",
    "        # 컬럼 타입 매핑\n",
    "        type_mapping = {\n",
    "            'int64': 'INT',\n",
    "            'float64': 'FLOAT', \n",
    "            'object': 'TEXT',\n",
    "            'datetime64[ns]': 'DATETIME'\n",
    "        }\n",
    "        \n",
    "        # CREATE TABLE 쿼리 생성\n",
    "        columns = []\n",
    "        for col in df.columns:\n",
    "            col_type = type_mapping.get(str(df[col].dtype), 'TEXT')\n",
    "            columns.append(f\"`{col}` {col_type}\")\n",
    "            \n",
    "        create_table_query = f\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "            {', '.join(columns)}\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        cursor.execute(create_table_query)\n",
    "        connection.commit()\n",
    "        print(f\"테이블 {table_name} 생성 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"테이블 생성 중 에러 발생: {e}\")\n",
    "        raise e\n",
    "\n",
    "def insert_csv_to_db(connection, csv_file_path: str, table_name: str):\n",
    "    \"\"\"\n",
    "    CSV 파일의 데이터를 데이터베이스 테이블에 삽입하는 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 진행상황 파일 경로\n",
    "        progress_file = f\"{table_name}_import_progress.txt\"\n",
    "        \n",
    "        # 이전 진행상황 확인\n",
    "        start_idx = 0\n",
    "        if os.path.exists(progress_file):\n",
    "            with open(progress_file, 'r') as f:\n",
    "                start_idx = int(f.read().strip() or 0)\n",
    "        \n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        \n",
    "        # NaN 값과 'nan' 문자열을 None으로 변환\n",
    "        df = df.replace({pd.NA: None, pd.NaT: None})\n",
    "        df = df.replace('nan', None) # 문자열 'nan'을 별도로 처리\n",
    "        df = df.where(pd.notnull(df), None)\n",
    "        \n",
    "        cursor = connection.cursor()\n",
    "        \n",
    "        # 청크 단위로 데이터 삽입\n",
    "        chunk_size = 1000\n",
    "        total_rows = len(df)\n",
    "        \n",
    "        for i in range(start_idx, total_rows, chunk_size):\n",
    "            chunk = df.iloc[i:min(i+chunk_size, total_rows)]\n",
    "            \n",
    "            # INSERT 쿼리 생성\n",
    "            placeholders = ', '.join(['%s'] * len(df.columns))\n",
    "            columns = '`, `'.join(df.columns)\n",
    "            insert_query = f\"INSERT INTO {table_name} (`{columns}`) VALUES ({placeholders})\"\n",
    "            \n",
    "            # 데이터 삽입\n",
    "            values = [tuple(None if pd.isna(x) else x for x in row) for row in chunk.values]\n",
    "            cursor.executemany(insert_query, values)\n",
    "            connection.commit()\n",
    "            \n",
    "            # 진행상황 저장\n",
    "            with open(progress_file, 'w') as f:\n",
    "                f.write(str(i + chunk_size))\n",
    "                \n",
    "            print(f\"진행률: {min((i + chunk_size) / total_rows * 100, 100):.2f}%\")\n",
    "            \n",
    "        print(f\"CSV 파일 {csv_file_path}의 데이터를 테이블 {table_name}에 삽입 완료\")\n",
    "        \n",
    "        # 작업 완료 후 진행상황 파일 삭제\n",
    "        if os.path.exists(progress_file):\n",
    "            os.remove(progress_file)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"데이터 삽입 중 에러 발생: {e}\")\n",
    "        raise e\n",
    "\n",
    "def csv_to_db(csv_file_path: str, table_name: str):\n",
    "    \"\"\"\n",
    "    CSV 파일을 데이터베이스 테이블로 변환하는 메인 함수\n",
    "    \"\"\"\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host='localhost',\n",
    "            port=3306,\n",
    "            database='cnu_data',\n",
    "            user='root',\n",
    "            password='dydrkfl#7!'\n",
    "        )\n",
    "        \n",
    "        # 테이블 생성\n",
    "        create_table_from_csv(connection, csv_file_path, table_name)\n",
    "        \n",
    "        # 데이터 삽입\n",
    "        insert_csv_to_db(connection, csv_file_path, table_name)\n",
    "        \n",
    "        connection.close()\n",
    "        print(\"데이터베이스 변환 작업 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"데이터베이스 변환 중 에러 발생: {e}\")\n",
    "        if 'connection' in locals():\n",
    "            connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "board_info 테이블 변환 시작...\n",
      "테이블 board_info 생성 완료\n",
      "진행률: 100.00%\n",
      "CSV 파일 board_info.csv의 데이터를 테이블 board_info에 삽입 완료\n",
      "데이터베이스 변환 작업 완료\n",
      "board_info 테이블 변환 완료\n"
     ]
    }
   ],
   "source": [
    "# CSV 파일들을 데이터베이스로 변환\n",
    "# board_info 테이블 변환\n",
    "print(\"\\nboard_info 테이블 변환 시작...\")\n",
    "try:\n",
    "    csv_to_db('board_info.csv', 'board_info')\n",
    "except Exception as e:\n",
    "    print(f\"board_info 테이블 변환 중 오류 발생: {e}\")\n",
    "print(\"board_info 테이블 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "lecture_plan 테이블 변환 시작...\n",
      "테이블 lecture_plan 생성 완료\n",
      "진행률: 2.54%\n",
      "진행률: 5.08%\n",
      "진행률: 7.62%\n",
      "진행률: 10.16%\n",
      "진행률: 12.70%\n",
      "진행률: 15.24%\n",
      "진행률: 17.78%\n",
      "진행률: 20.32%\n",
      "진행률: 22.86%\n",
      "진행률: 25.40%\n",
      "진행률: 27.94%\n",
      "진행률: 30.48%\n",
      "진행률: 33.03%\n",
      "진행률: 35.57%\n",
      "진행률: 38.11%\n",
      "진행률: 40.65%\n",
      "진행률: 43.19%\n",
      "진행률: 45.73%\n",
      "진행률: 48.27%\n",
      "진행률: 50.81%\n",
      "진행률: 53.35%\n",
      "진행률: 55.89%\n",
      "진행률: 58.43%\n",
      "진행률: 60.97%\n",
      "진행률: 63.51%\n",
      "진행률: 66.05%\n",
      "진행률: 68.59%\n",
      "진행률: 71.13%\n",
      "진행률: 73.67%\n",
      "진행률: 76.21%\n",
      "진행률: 78.75%\n",
      "진행률: 81.29%\n",
      "진행률: 83.83%\n",
      "진행률: 86.37%\n",
      "진행률: 88.91%\n",
      "진행률: 91.45%\n",
      "진행률: 93.99%\n",
      "진행률: 96.53%\n",
      "진행률: 99.08%\n",
      "진행률: 100.00%\n",
      "CSV 파일 lecture_plan.csv의 데이터를 테이블 lecture_plan에 삽입 완료\n",
      "데이터베이스 변환 작업 완료\n",
      "lecture_plan 테이블 변환 완료\n"
     ]
    }
   ],
   "source": [
    "# lecture_plan 테이블 변환  \n",
    "print(\"\\nlecture_plan 테이블 변환 시작...\")\n",
    "try:\n",
    "    csv_to_db('lecture_plan.csv', 'lecture_plan')\n",
    "except Exception as e:\n",
    "    print(f\"lecture_plan 테이블 변환 중 오류 발생: {e}\")\n",
    "print(\"lecture_plan 테이블 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sugang_info 테이블 변환 시작...\n",
      "테이블 sugang_info 생성 완료\n",
      "진행률: 3.93%\n",
      "진행률: 7.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진행률: 11.79%\n",
      "진행률: 15.71%\n",
      "진행률: 19.64%\n",
      "진행률: 23.57%\n",
      "진행률: 27.50%\n",
      "진행률: 31.43%\n",
      "진행률: 35.36%\n",
      "진행률: 39.29%\n",
      "진행률: 43.22%\n",
      "진행률: 47.14%\n",
      "진행률: 51.07%\n",
      "진행률: 55.00%\n",
      "진행률: 58.93%\n",
      "진행률: 62.86%\n",
      "진행률: 66.79%\n",
      "진행률: 70.72%\n",
      "진행률: 74.64%\n",
      "진행률: 78.57%\n",
      "진행률: 82.50%\n",
      "진행률: 86.43%\n",
      "진행률: 90.36%\n",
      "진행률: 94.29%\n",
      "진행률: 98.22%\n",
      "진행률: 100.00%\n",
      "CSV 파일 sugang_info.csv의 데이터를 테이블 sugang_info에 삽입 완료\n",
      "데이터베이스 변환 작업 완료\n",
      "sugang_info 테이블 변환 완료\n"
     ]
    }
   ],
   "source": [
    "# sugang_info 테이블 변환\n",
    "print(\"\\nsugang_info 테이블 변환 시작...\")\n",
    "try:\n",
    "    csv_to_db('sugang_info.csv', 'sugang_info')\n",
    "except Exception as e:\n",
    "    print(f\"sugang_info 테이블 변환 중 오류 발생: {e}\")\n",
    "print(\"sugang_info 테이블 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sugang_info 테이블 컬럼 삭제 시작...\n",
      "삭제할 컬럼이 존재하지 않습니다.\n"
     ]
    }
   ],
   "source": [
    "# sugang_info 테이블에서 미사용중인 tlsn_aply_dt와 api_call_idx 컬럼 삭제\n",
    "print(\"\\nsugang_info 테이블 컬럼 삭제 시작...\")\n",
    "try:\n",
    "    connection = mysql.connector.connect(\n",
    "        host='localhost',\n",
    "        user='root', \n",
    "        password='dydrkfl#7!',\n",
    "        database='cnu_data'\n",
    "    )\n",
    "    \n",
    "    with connection.cursor() as cursor:\n",
    "        # 컬럼 존재 여부 확인 후 삭제\n",
    "        cursor.execute(\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'sugang_info' AND TABLE_SCHEMA = 'cnu_data'\")\n",
    "        columns = [column[0] for column in cursor.fetchall()]\n",
    "        \n",
    "        columns_to_drop = ['tlsn_aply_dt', 'api_call_idx', 'cnt', 'pagecnt']\n",
    "        existing_columns = [col for col in columns_to_drop if col in columns]\n",
    "        \n",
    "        if existing_columns:\n",
    "            drop_query = f\"ALTER TABLE sugang_info DROP COLUMN {', DROP COLUMN '.join(existing_columns)}\"\n",
    "            cursor.execute(drop_query)\n",
    "            connection.commit()\n",
    "            print(f\"컬럼 삭제 완료: {', '.join(existing_columns)}\")\n",
    "        else:\n",
    "            print(\"삭제할 컬럼이 존재하지 않습니다.\")\n",
    "        \n",
    "    connection.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"컬럼 삭제 중 오류 발생: {e}\")\n",
    "    if 'connection' in locals():\n",
    "        connection.close()\n",
    "    print(f\"컬럼 삭제 중 오류 발생: {e}\")\n",
    "    if 'connection' in locals():\n",
    "        connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "kocw_lecture 테이블 변환 시작...\n",
      "테이블 kocw_lecture 생성 완료\n",
      "진행률: 31.28%\n",
      "진행률: 62.56%\n",
      "진행률: 93.84%\n",
      "진행률: 100.00%\n",
      "CSV 파일 kocw_lecture_utf8.csv의 데이터를 테이블 kocw_lecture에 삽입 완료\n",
      "데이터베이스 변환 작업 완료\n",
      "kocw_lecture 테이블 변환 완료\n"
     ]
    }
   ],
   "source": [
    "# kocw_lecture 테이블 변환\n",
    "print(\"\\nkocw_lecture 테이블 변환 시작...\")\n",
    "try:\n",
    "    csv_to_db('kocw_lecture_utf8.csv', 'kocw_lecture')\n",
    "except Exception as e:\n",
    "    print(f\"kocw_lecture 테이블 변환 중 오류 발생: {e}\")\n",
    "print(\"kocw_lecture 테이블 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "major_interview 테이블 변환 시작...\n",
      "테이블 생성 완료\n",
      "데이터 변환 완료\n",
      "major_interview 테이블 변환 완료\n"
     ]
    }
   ],
   "source": [
    "# major_interview 테이블 변환 \n",
    "print(\"\\nmajor_interview 테이블 변환 시작...\")\n",
    "try:\n",
    "    # major_professor와 major_interview 테이블 생성을 위한 함수 정의\n",
    "    def create_major_tables():\n",
    "        try:\n",
    "            connection = mysql.connector.connect(\n",
    "                host='localhost',\n",
    "                user='root',\n",
    "                password='dydrkfl#7!', \n",
    "                database='cnu_data'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # 기존 테이블이 있다면 삭제\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS major_interview\")\n",
    "            cursor.execute(\"DROP TABLE IF EXISTS major_professor\")\n",
    "\n",
    "            # major_professor 테이블 생성\n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS major_professor (\n",
    "                    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                    number INT,\n",
    "                    interview_title VARCHAR(200),\n",
    "                    professor_position VARCHAR(100)\n",
    "                ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
    "            \"\"\")\n",
    "\n",
    "            # major_interview 테이블 생성 \n",
    "            cursor.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS major_interview (\n",
    "                    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                    professor_id INT,\n",
    "                    question TEXT,\n",
    "                    answer TEXT, \n",
    "                    sequence INT,\n",
    "                    FOREIGN KEY (professor_id) REFERENCES major_professor(id)\n",
    "                ) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci\n",
    "            \"\"\")\n",
    "\n",
    "            connection.commit()\n",
    "            print(\"테이블 생성 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"테이블 생성 중 오류 발생: {e}\")\n",
    "        finally:\n",
    "            if connection.is_connected():\n",
    "                cursor.close()\n",
    "                connection.close()\n",
    "\n",
    "    def process_csv_data():\n",
    "        try:\n",
    "            connection = mysql.connector.connect(\n",
    "                host='localhost',\n",
    "                user='root',\n",
    "                password='dydrkfl#7!',\n",
    "                database='cnu_data'\n",
    "            )\n",
    "            cursor = connection.cursor()\n",
    "\n",
    "            # CSV 파일 읽기\n",
    "            df = pd.read_csv('major_interview_utf8.csv', encoding='utf-8')\n",
    "\n",
    "            # 각 행 처리\n",
    "            for index, row in df.iterrows():\n",
    "                # major_professor 데이터 삽입\n",
    "                insert_prof_sql = \"\"\"\n",
    "                    INSERT INTO major_professor (number, interview_title, professor_position)\n",
    "                    VALUES (%s, %s, %s)\n",
    "                \"\"\"\n",
    "                prof_values = (\n",
    "                    int(row['연번']) if pd.notna(row['연번']) else None,\n",
    "                    str(row['인터뷰제목']) if pd.notna(row['인터뷰제목']) else None,\n",
    "                    str(row['인터뷰이 직업(직위)']) if pd.notna(row['인터뷰이 직업(직위)']) else None\n",
    "                )\n",
    "                cursor.execute(insert_prof_sql, prof_values)\n",
    "                professor_id = cursor.lastrowid\n",
    "\n",
    "                # 질문-답변 쌍 처리\n",
    "                for sequence in range(1, 19):  # 1부터 18까지\n",
    "                    q_col = f'질문_{sequence}'\n",
    "                    a_col = f'답변_{sequence}'\n",
    "                    \n",
    "                    if q_col in row.index and pd.notna(row[q_col]):\n",
    "                        insert_qa_sql = \"\"\"\n",
    "                            INSERT INTO major_interview (professor_id, question, answer, sequence)\n",
    "                            VALUES (%s, %s, %s, %s)\n",
    "                        \"\"\"\n",
    "                        qa_values = (\n",
    "                            professor_id,\n",
    "                            str(row[q_col]) if pd.notna(row[q_col]) else None,\n",
    "                            str(row[a_col]) if pd.notna(row[a_col]) else None,\n",
    "                            sequence\n",
    "                        )\n",
    "                        cursor.execute(insert_qa_sql, qa_values)\n",
    "\n",
    "            connection.commit()\n",
    "            print(\"데이터 변환 완료\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"데이터 처리 중 오류 발생: {e}\")\n",
    "        finally:\n",
    "            if connection.is_connected():\n",
    "                cursor.close() \n",
    "                connection.close()\n",
    "\n",
    "    # 테이블 생성 및 데이터 처리 실행\n",
    "    create_major_tables()\n",
    "    process_csv_data()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"major_interview 테이블 변환 중 오류 발생: {e}\")\n",
    "print(\"major_interview 테이블 변환 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "departments 테이블 생성 및 데이터 삽입 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # departments 테이블 생성\n",
    "    create_departments_table = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS departments (\n",
    "        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "        college VARCHAR(100),\n",
    "        department VARCHAR(100),\n",
    "        UNIQUE KEY college_dept (college, department)\n",
    "    )\n",
    "    \"\"\"\n",
    "    cursor.execute(create_departments_table)\n",
    "\n",
    "    # lecture_plan에서 distinct college, department 조회 후 departments 테이블에 삽입\n",
    "    insert_departments = \"\"\"\n",
    "    INSERT IGNORE INTO departments (college, department)\n",
    "    SELECT DISTINCT college, department \n",
    "    FROM lecture_plan\n",
    "    WHERE college IS NOT NULL \n",
    "    AND department IS NOT NULL\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_departments)\n",
    "    \n",
    "    connection.commit()\n",
    "    print(\"departments 테이블 생성 및 데이터 삽입 완료\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"departments 테이블 처리 중 오류 발생: {e}\")\n",
    "finally:\n",
    "    if connection.is_connected():\n",
    "        cursor.close()\n",
    "        connection.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
