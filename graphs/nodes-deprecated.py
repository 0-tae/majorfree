from graphs.graph_status import GraphStatus
from mcp_server_api import get_multi_server_mcp_clients_from_api
from langchain_mcp_adapters.client import MultiServerMCPClient
from langgraph.prebuilt import create_react_agent
from graphs.nodes.node_utils import node

from tools.mcp.llm_models.chat_gpt import model_instance as chat_gpt
from tools.mcp.vectordb.chroma.chroma_db import db_instance as chroma_db

@node
async def init(state: GraphStatus) -> GraphStatus:
    """
    ì´ˆê¸° ìƒíƒœ ì„¤ì • ë¡œì§ ìžˆìœ¼ë©´ ì¶”ê°€í•  ê²ƒ
    """

    """
    1. ê·œì¹™ & ê°€ì´ë“œë¼ì¸
    - ë‹¹ì‹ ì€ 30ë…„ ê·¼ì†ì˜ ì¶©ë‚¨ëŒ€í•™êµ êµìœ¡ ì¢…ì‚¬ìžìž…ë‹ˆë‹¤. ëŒ€í•™êµ ì‹ ìž…ìƒ, í˜¹ì€ ì§„ë¡œ ë° ì „ê³µ ê²°ì •ì— ì–´ë ¤ì›€ì„ ê²ªëŠ” í•™ìƒë“¤ì—ê²Œ ì¹œì ˆí•˜ê²Œ ëŒ€ë‹µí•´ì£¼ì„¸ìš”.
    - í•™ê³¼ ê³¼ëª©ì— ëŒ€í•œ í• ë£¨ì‹œë„¤ì´ì…˜ì„ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì˜í•œ ê³¼ëª©ì„ ì–¸ê¸‰í•´ì•¼ í•©ë‹ˆë‹¤.
    - ëª¨ë“  ë§ì—ëŠ” í•œêµ­ì–´ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”. ì´ì „ ëŒ€í™”ë‚´ì—­ì„ ì°¸ê³ í•˜ì—¬ ê°€ìž¥ ìµœê·¼ì˜ ë©”ì‹œì§€ì— ëŒ€í•´ ë‹µë³€í•˜ì„¸ìš”.
    
    2. ì•„ëž˜ ì„¤ëª…ì— ëŒ€í•˜ì—¬ ì‚¬ìš©ìž ì§ˆë¬¸ê³¼ ì—°ê´€ëœ ì ì ˆí•œ ì„œë¹„ìŠ¤ê°€ ìžˆë‹¤ê³  íŒë‹¨ë˜ë©´, ì‚¬ìš©ìžê°€ ì˜ë„í•˜ê³ ìž í•˜ëŠ” ë™ìž‘ê³¼ ì„œë¹„ìŠ¤ ì„¤ëª…ì„ ì—°ê´€ì§€ì–´ ì•„ëž˜ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©ìžì—ê²Œ ì¶”ì²œí•˜ì„¸ìš”.
    - í•™ê³¼ ì •ë³´ íƒìƒ‰ ì„œë¹„ìŠ¤ : ê´€ì‹¬ìžˆëŠ” í•™ê³¼ì™€ ê´€ë ¨ëœ í•µì‹¬ í¬ì¸íŠ¸, í•„ìš”í•œ ì—­ëŸ‰, ì§„ë¡œ ë°©í–¥ì„ íŒŒì•…í•  ìˆ˜ ìžˆìœ¼ë©°, í•™ìƒë“¤ì´ ì¼ë°˜ì ìœ¼ë¡œ ê¶ê¸ˆí•´ í•  ì •ë³´ë¥¼ ì „ê³µ êµìˆ˜ë‹˜ ì¸í„°ë·° ê¸°ë°˜ì˜ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
    - í•™ê³¼ë³„ ì»¤ë¦¬í˜ëŸ¼ ì„œë¹„ìŠ¤ : ì¶©ë‚¨ëŒ€í•™êµì—ì„œ ê°œì„¤ëœ ì „ê³µê³¼ëª©ì„ ë°”íƒ•ìœ¼ë¡œ ìœ ì‚¬í•œ KOCW ê°•ì˜, ìœ íŠœë¸Œ ê°•ì˜, ì›¹ ê²€ìƒ‰ í•™ìŠµ ìžë£Œë¥¼ ì°¾ì•„ ì œê³µí•©ë‹ˆë‹¤.
    - ì±„íŒ… ì„œë¹„ìŠ¤ : ê´€ì‹¬ìžˆëŠ” í•™ê³¼ í•™ìƒë“¤ì´ ê°€ìž¥ ë§Žì´ ë“£ëŠ” ê³¼ëª©ì— ëŒ€í•´ ë¬¼ì–´ë³´ê³ , í•´ë‹¹ í•™ê³¼ì— 3í•™ë…„, 4í•™ë…„ ê³¼ëª©ì´ ì–´ë–¤ ê²ƒë“¤ì´ ìžˆëŠ”ì§€ë„ í™•ì¸í•´ë³´ì„¸ìš”.
    
    3. ì‚¬ìš©ìžì˜ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ë‹¤ìŒ ì§ˆë¬¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”. ì¶”ì²œ ì§ˆë¬¸ì€ ì‚¬ìš©ìžì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
    """
    
    prompt = '''
    1. rules & guidelines
    - You are a staff member of education department with 30 years of experience at ì¶©ë‚¨ëŒ€í•™êµ(Chungnam National University). 
    - Please kindly answer questions from new university students or those struggling with career and major decisions.
    - Do not hallucinate or invent any courses; only mention courses based on the provided context.
    - Always respond in Korean. Refer to the most recent message in the conversation for your answer.
    
    2. If you determine that there is a suitable service related to the userâ€™s question as described below, recommend the relevant service by connecting the intended action of the user with the following service descriptions
    but, If sufficient information has already been provided to the user, you do not need to recommend the services described below. :
    - í•™ê³¼ ì •ë³´ íƒìƒ‰ ì„œë¹„ìŠ¤: Provides answers to questions about key points, required competencies, and career paths related to the department of interest, using information based on interviews with professors, as well as information that students are generally curious about.
	- í•™ê³¼ë³„ ì»¤ë¦¬í˜ëŸ¼ ì„œë¹„ìŠ¤: Offers similar KOCW lectures, YouTube lectures, and web-based study materials based on major courses offered at Chungnam National University.
	- ì±—ë´‡ ì±„íŒ… ì„œë¹„ìŠ¤: Enables users to ask about the most popular courses taken by students in their department of interest, and to check which courses are available for third- and fourth-year students in that department.
    
    3. Based on the userâ€™s question, recommend an appropriate follow-up question. The recommended question should be relevant to the userâ€™s original inquiry.
    '''
    
    system_message = {"role":"system", "content": prompt}
    user_message = {"role":"user", "content": state["instruction"]}
    
    # ë§Œì•½ ì´ì „ ëŒ€í™”ë‚´ì—­ì´ ìžˆë‹¤ë©´ ë§¨ ì•žì— í”„ë¡¬í”„íŠ¸ë¥¼ ì‚½ìž…í•œ í›„ ìœ ì € ì§ˆë¬¸ì„ ë„£ê³  ê·¸ëŒ€ë¡œ ë¦¬í„´í•˜ê¸°
    if state["messages"]:
        state["messages"].insert(0, system_message)
        return {
            "messages": [user_message]
        }
    
    return {
        "messages": [system_message, user_message]
    }


@node
async def route(state: GraphStatus) -> GraphStatus:
    """
    ë¼ìš°íŒ… ë¡œì§ ìžˆìœ¼ë©´ ì¶”ê°€í•  ê²ƒ
    """
    
    available_modes = [
        "YOUTUBE_SEARCH",
        "WEB_SEARCH",
        "KOCW_SEARCH",
        "DEPARTMENT_SEARCH",
        "FAST_FORWARD"
    ]
    
    for mode in available_modes:
        if mode == state["search_type"]:
            return mode
        
    return "COMMON"

@node
async def fast_forward_question(state: GraphStatus) -> GraphStatus:
    """
    ë¹ ë¥¸ ì§ˆë¬¸
    """
    
    model = chat_gpt
    
    prompt = None
    
    answer = model.query_by_single_instruction(state["instruction"])

    return {
        "answer": answer
    }

@node
async def agent_question(state: GraphStatus) -> GraphStatus:
    client_config = await get_multi_server_mcp_clients_from_api()
    
    client = MultiServerMCPClient(client_config)
    
    model = chat_gpt.get_model()
    
    # í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    tools = await client.get_tools()
        
    agent = create_react_agent(model=model,
                            tools=tools,
                            state_schema=GraphStatus)
    
    result = await agent.ainvoke({
        "messages": state["messages"]
    })
    
    print("ðŸ˜‡ RESULT: ",result)
    
    answer =  result.get("messages")[-1].content if result.get("messages") else "No response"
    generated_message = {"role":"assistant", "content": answer}

    return {
        "messages": [generated_message],
        "answer": answer
    }

@node
async def youtube_search(state: GraphStatus) -> GraphStatus:
    """
    ìœ íŠœë¸Œ ê²€ìƒ‰ì„ í•˜ëŠ” ë‹¨ê³„
    """
    client_config = await get_multi_server_mcp_clients_from_api()
    
    client = MultiServerMCPClient(client_config)
    
    model = chat_gpt.get_model()
    
    tools = await client.get_tools(server_name="youtube_search_mcp")
    
    agent = create_react_agent(model=model,
                            tools=tools,
                            state_schema=GraphStatus)
    
    prompt = f'''
    Search for 7 YouTube videos related to the instruction.
    For each video, provide the video title, link, thumbnail, and a clear description.
    Exclude negative or inappropriate content and explain how such content was filtered out.
    instruction: {state["instruction"]}
    '''
    
    state["messages"] += [{"role":"user", "content": prompt}]
        
    result = await agent.ainvoke({
        "messages": [{"role":"user", "content": prompt}]
    })
    
    print("ðŸ˜‡ YOUTUBE SEARCH RESULT: ",result)
    
    answer =  result.get("messages")[-1].content if result.get("messages") else "No response"
    generated_message = {"role":"assistant", "content": answer}

    return {
        "messages": [generated_message],
        "answer": answer
    }
    
@node
async def kocw_search(state: GraphStatus) -> GraphStatus:
    """
    í•™ìŠµìžë£Œ ì¶”ì²œ
    """
    client_config = await get_multi_server_mcp_clients_from_api()
    
    client = MultiServerMCPClient(client_config)
    
    model = chat_gpt.get_model()
    
    tools = await client.get_tools(server_name="kocw_lecture_search_mcp")
            
    agent = create_react_agent(model=model,
                            tools=tools,
                            state_schema=GraphStatus)
    
    instruction = state["instruction"]
    
    result = await agent.ainvoke({
        "messages": [{"role":"user", "content":instruction}]
    })
    
    print("ðŸ˜‡ RESULT: ",result)
        
    answer =  result.get("messages")[-1].content if result.get("messages") else "No response"
    generated_message = {"role":"assistant", "content": answer}

    print(result)

    return {
        "messages": [generated_message],
        "answer": answer
    }
    
@node
async def department_search(state: GraphStatus) -> GraphStatus:
    """
    í•™ê³¼ ì •ë³´ íƒìƒ‰ì„ í•˜ëŠ” ë‹¨ê³„
    """
    model = chat_gpt
    
    instruction = state["instruction"]
    optional_args = state["optional_args"]
    
    department = optional_args.get("department")
    
    context = retreive(instruction=instruction, department=department)
    
    prompt = f'''Please answer the following question using the provided context information.
                Please follow these guidelines when generating your response:
                    1. Mandatory source citation for all content derived from the provided context
                    2. Format citations as "**[id, question(in context, not instruction), answer]**" after each relevant information
                    3. Distinguish between different sources when using information from multiple references
                    4. Clearly indicate when using general knowledge by noting "commonly known fact" or "general knowledge"
                
                Please respond in Korean.
                
                ### Question
                {instruction}
                
                ### Context
                {context}'''
            
    answer = model.query_by_single_instruction(prompt)
    generated_message = {"role":"assistant", "content": answer}

    return {
        "messages": [generated_message],
        "answer": answer
    }

def retreive(instruction: str, department: str = None) -> str:
    retreive_result = chroma_db.query(input = instruction, filter=[department], n_results=10)
    return retreive_result
    
@node
async def web_search(state: GraphStatus) -> GraphStatus:
    """
    ì›¹ ê²€ìƒ‰ì„ í•˜ëŠ” ë‹¨ê³„
    """
    
    client_config = await get_multi_server_mcp_clients_from_api()
    
    client = MultiServerMCPClient(client_config)
    
    model = chat_gpt.get_model()
    
    tools = await client.get_tools(server_name="naver_search_mcp")
    
    agent = create_react_agent(model=model,
                            tools=tools,
                            state_schema=GraphStatus)
    
    prompt = f'''
    Search for information about the question. Please cite the sources of search results and respond in Korean.
    Question: {state["instruction"]}
    '''
    question_message = {"role":"user", "content": prompt}
    state["messages"] += [question_message]
        
    result = await agent.ainvoke({
        "messages": [question_message]
    })
        
    answer =  result.get("messages")[-1].content if result.get("messages") else "No response"
    generated_message = {"role":"assistant", "content": answer}

    return {
        "messages": [generated_message],
        "answer": answer
    }

@node
async def merge_messages(state: GraphStatus) -> GraphStatus:
    """
    ë©”ì‹œì§€ë¥¼ ë³‘í•©í•˜ëŠ” ë‹¨ê³„
    """
    
    model = chat_gpt
    
    prompt = f'''
    Please reconstruct the message content based on the conversation history so far. 
    
    Please structure your response so that it directly answers the user's most recent question.
    
    If the assistant suggests videos or external links related to the instruction, please provide accessible links to those contents.    
    
    instruction: {state["instruction"]}
    
    You can be a formatting assistant. For each video entry, apply the following rules:

    1. Wrap the entire video block with [[VIDEO]] and [[/VIDEO]].
    2. If a **title** exists, wrap it with [[TITLE]] and [[/TITLE]].
    3. If a **URL/link** exists, wrap it with [[LINK]] and [[/LINK]].
    4. If a **thumbnail** exists, wrap it with [[THUMBNAIL]] and [[/THUMBNAIL]].
    5. If there is any remaining **description or metadata**, place it outside the above tags and wrap it with [[DESCRIPTION]] and [[/DESCRIPTION]].
    6. If any of the title, link, or thumbnail is **missing**, do not include their corresponding tags at all.
    7. Repeat this structure for each video item in the input.

    Only output the properly tagged content. Do not add explanations or comments. Do this consistently for all videos in the list. 
    DESCRIPTION must be in Korean.
    
    Example:
    [[VIDEO]]
    [[LINK]]https://www.youtube.com/watch?v=abc123[[/LINK]]
    [[TITLE]]How to Learn Python in 2025[[/TITLE]]
    [[THUMBNAIL]]https://img.youtube.com/vi/abc123/hqdefault.jpg[[/THUMBNAIL]]
    [[DESCRIPTION]]This video is a beginner-friendly guide to learning Python. Uploaded by CodeAcademy. Duration: 12:34. Views: 1.2M[[/DESCRIPTION]]
    [[/VIDEO]]

    '''
    
    state["messages"] += [{"role":"user", "content": prompt}]
    
    result = model.query_by_messages(state["messages"])
    
    answer =  result
    generated_message = {"role":"assistant", "content": answer}
    
    
    return {
        "messages": [generated_message],
        "answer": answer
    }