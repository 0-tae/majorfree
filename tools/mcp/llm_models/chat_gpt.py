from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from typing import List, Dict, Any
import json, os

class ChatGPTModel:
    """
    ChatGPT APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ëª¨ë¸ í´ë˜ìŠ¤
    """
    def __init__(self, model: str = "gpt-4o-mini"):
        base_dir = os.path.dirname(os.path.abspath(__file__))  # chat_gpt.pyì˜ ê²½ë¡œ ê¸°ì¤€
        config_path = os.path.join(base_dir, "llm_config.json")
        
        with open(config_path) as f:
            llm_config = json.load(f)
            
        self.model = ChatOpenAI(model=model, 
                            temperature=0,
                            api_key=llm_config["OPENAI_API_KEY"])
    
    def get_model(self):
        return self.model
    
    def query_by_single_instruction(self, instruction: str) -> str:
        """
        ChatGPTì— ë‹¨ìˆœ ì§ˆì˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        
        try:
            response = self.model.invoke([instruction])
            print("ğŸ¤– GPT RESPONSE(SINGLE_INSTRUCTION):",response.content)
            return response.content
        except Exception as e:
            raise Exception(f"ChatGPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
    def query_by_messages(self, messages: List[Dict[str, Any]]) -> str:
        """
        ChatGPTì— ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì§ˆì˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        try:
            # Dict í˜•íƒœì˜ ë©”ì‹œì§€ë“¤ì„ LangChain Message ê°ì²´ë¡œ ë³€í™˜
            langchain_messages = []
            
            for msg in messages:
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if role == "system":
                    langchain_messages.append(SystemMessage(content=content))
                elif role == "user":
                    langchain_messages.append(HumanMessage(content=content))
                elif role == "assistant":
                    langchain_messages.append(AIMessage(content=content))
            
            # ë³€í™˜ëœ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ invokeì— ì „ë‹¬ (ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì§€ ì•ŠìŒ!)
            response = self.model.invoke(langchain_messages)
            
            print("ğŸ¤– GPT RESPONSE(MESSAGES):",response.content)
            
            return response.content
            
        except Exception as e:
            raise Exception(f"ChatGPT API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

    async def stream_query_by_messages(self, messages: List[Dict[str, Any]]) -> str:
        """
        ChatGPTì— ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¡œ ì§ˆì˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        try:
            # Dict í˜•íƒœì˜ ë©”ì‹œì§€ë“¤ì„ LangChain Message ê°ì²´ë¡œ ë³€í™˜
            langchain_messages = []
            
            for msg in messages:
                role = msg.get("role", "")
                content = msg.get("content", "")
                
                if role == "system":
                    langchain_messages.append(SystemMessage(content=content))
                elif role == "user":
                    langchain_messages.append(HumanMessage(content=content))
                elif role == "assistant":
                    langchain_messages.append(AIMessage(content=content))
            
        
            async for chunk in self.model.astream(langchain_messages):
                # chunkëŠ” AIMessageChunkì´ë©° .content ë˜ëŠ” .text ì‚¬ìš© ê°€ëŠ¥
                # ë¶€ë¶„ í† í°ë§Œ í¬í•¨ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëˆ„ì ì€ í˜¸ì¶œì ì¸¡ì—ì„œ ìˆ˜í–‰
                yield chunk
            
        except Exception as e:
            raise Exception(f"ChatGPT API ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
model_instance = ChatGPTModel()